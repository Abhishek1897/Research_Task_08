{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71a1a5a",
   "metadata": {},
   "source": [
    "# analyze_bias.ipynb\n",
    "Quantitative + qualitative analyses on `./results/responses.csv`.\n",
    "\n",
    "**Outputs:**\n",
    "- `analysis/analysis_summary.json`\n",
    "- `analysis/chi_square_results.json`\n",
    "\n",
    "This notebook version mirrors the Python script and is safe to run inside Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd35044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete. Ready to analyze results/responses.csv\n"
     ]
    }
   ],
   "source": [
    "import csv, json, re, math\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Use current directory for Jupyter friendliness\n",
    "ROOT = Path('.')\n",
    "RESP = ROOT / 'results' / 'responses.csv'\n",
    "OUT_DIR = ROOT / 'analysis'\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Minimal sentiment lexicon (extend as needed)\n",
    "POS = set(\"improve improving growth potential breakout strong efficient efficiency excellent good great positive opportunity opportunities upside\".split())\n",
    "NEG = set(\"poor struggle struggling weak decline declining worse worst negative risk downside issue issues problem problems\".split())\n",
    "\n",
    "PLAYER_PATTERN = re.compile(r\"(player\\s+[A-Z]|Player\\s+[A-Z])\", re.I)\n",
    "\n",
    "def sentiment_score(text):\n",
    "    tokens = re.findall(r\"[A-Za-z']+\", text.lower())\n",
    "    pos = sum(t in POS for t in tokens)\n",
    "    neg = sum(t in NEG for t in tokens)\n",
    "    return pos - neg\n",
    "\n",
    "def chi_square(observed_counts_by_group):\n",
    "    \"\"\"\n",
    "    observed_counts_by_group: dict[group] -> Counter(category->count)\n",
    "    Returns chi2, dof, expected matrix for reference.\n",
    "    \"\"\"\n",
    "    groups = list(observed_counts_by_group.keys())\n",
    "    cats = sorted({c for g in groups for c in observed_counts_by_group[g]})\n",
    "    # Build table\n",
    "    table = []\n",
    "    row_sums = []\n",
    "    for g in groups:\n",
    "        row = [observed_counts_by_group[g].get(c,0) for c in cats]\n",
    "        table.append(row)\n",
    "        row_sums.append(sum(row))\n",
    "    col_sums = [sum(row[i] for row in table) for i in range(len(cats))]\n",
    "    total = sum(col_sums)\n",
    "    chi2 = 0.0\n",
    "    for r,g in enumerate(groups):\n",
    "        for i,c in enumerate(cats):\n",
    "            expected = (row_sums[r]*col_sums[i])/total if total>0 else 0\n",
    "            observed = table[r][i]\n",
    "            if expected > 0:\n",
    "                chi2 += (observed-expected)**2/expected\n",
    "    dof = (len(groups)-1)*(len(cats)-1)\n",
    "    return {\"chi2\": chi2, \"dof\": dof, \"groups\": groups, \"categories\": cats, \"table\": table, \"row_sums\": row_sums, \"col_sums\": col_sums, \"total\": total}\n",
    "\n",
    "print('✅ Setup complete. Ready to analyze results/responses.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419ac677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote analysis/analysis_summary.json and analysis/chi_square_results.json\n"
     ]
    }
   ],
   "source": [
    "# Run analysis\n",
    "if not RESP.exists():\n",
    "    print(\"No responses.csv found. Add responses via run_experiment (notebook or .py) and re-run this cell.\")\n",
    "else:\n",
    "    rows = []\n",
    "    with open(RESP, encoding='utf-8') as f:\n",
    "        for i, row in enumerate(csv.DictReader(f)):\n",
    "            rows.append(row)\n",
    "\n",
    "    # Buckets\n",
    "    sentiment_by_h = defaultdict(list)\n",
    "    mentions_by_h = defaultdict(Counter)\n",
    "    reco_bucket_by_h = defaultdict(Counter)\n",
    "\n",
    "    for r in rows:\n",
    "        h = r.get('hypothesis_id','')\n",
    "        txt = r.get('response_text','')\n",
    "        # sentiment\n",
    "        sentiment_by_h[h].append(sentiment_score(txt))\n",
    "        # mentions\n",
    "        for m in PLAYER_PATTERN.findall(txt):\n",
    "            k = m.strip().title()\n",
    "            mentions_by_h[h][k] += 1\n",
    "        # reco types\n",
    "        low = txt.lower()\n",
    "        if 'offense' in low: reco_bucket_by_h[h]['offense'] += 1\n",
    "        if 'defense' in low: reco_bucket_by_h[h]['defense'] += 1\n",
    "        if 'team' in low:    reco_bucket_by_h[h]['team'] += 1\n",
    "        if re.search(r\"\\bplayer\\b\", low): reco_bucket_by_h[h]['individual'] += 1\n",
    "\n",
    "    summary = {\n",
    "        'n_rows': len(rows),\n",
    "        'sentiment_mean_by_hypothesis': {h: (sum(v)/len(v) if v else 0.0) for h,v in sentiment_by_h.items()},\n",
    "        'mentions_by_hypothesis': {h: dict(c) for h,c in mentions_by_h.items()},\n",
    "        'recommendation_buckets_by_hypothesis': {h: dict(c) for h,c in reco_bucket_by_h.items()},\n",
    "    }\n",
    "\n",
    "    pairs = [(\"H1_framing_negative\",\"H1_framing_positive\"),\n",
    "             (\"H3_confirmation_neutral\",\"H3_confirmation_primed\")]\n",
    "    chi_results = {}\n",
    "    for a,b in pairs:\n",
    "        observed = {\n",
    "            a: reco_bucket_by_h.get(a, Counter()),\n",
    "            b: reco_bucket_by_h.get(b, Counter())\n",
    "        }\n",
    "        chi_results[f\"{a}_vs_{b}\"] = chi_square(observed)\n",
    "\n",
    "    (OUT_DIR / 'analysis_summary.json').write_text(json.dumps(summary, indent=2))\n",
    "    (OUT_DIR / 'chi_square_results.json').write_text(json.dumps(chi_results, indent=2))\n",
    "    print('Wrote analysis/analysis_summary.json and analysis/chi_square_results.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2a0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis_summary.json:\n",
      "{\n",
      "  \"n_rows\": 10,\n",
      "  \"sentiment_mean_by_hypothesis\": {\n",
      "    \"\": 0.0,\n",
      "    \"H1\": 0.5,\n",
      "    \"H2\": 0.0,\n",
      "    \"H3\": 0.0,\n",
      "    \"H4\": 0.0\n",
      "  },\n",
      "  \"mentions_by_hypothesis\": {\n",
      "    \"H1\": {\n",
      "      \"Player A\": 2\n",
      "    }\n",
      "  },\n",
      "  \"recommendation_buckets_by_hypothesis\": {\n",
      "    \"H1\": {\n",
      "      \"individual\": 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "chi_square_results.json:\n",
      "{\n",
      "  \"H1_framing_negative_vs_H1_framing_positive\": {\n",
      "    \"chi2\": 0.0,\n",
      "    \"dof\": -1,\n",
      "    \"groups\": [\n",
      "      \"H1_framing_negative\",\n",
      "      \"H1_framing_positive\"\n",
      "    ],\n",
      "    \"categories\": [],\n",
      "    \"table\": [\n",
      "      [],\n",
      "      []\n",
      "    ],\n",
      "    \"row_sums\": [\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    \"col_sums\": [],\n",
      "    \"total\": 0\n",
      "  },\n",
      "  \"H3_confirmation_neutral_vs_H3_confirmation_primed\": {\n",
      "    \"chi2\": 0.0,\n",
      "    \"dof\": -1,\n",
      "    \"groups\": [\n",
      "      \"H3_confirmation_neutral\",\n",
      "      \"H3_confirmation_primed\"\n",
      "    ],\n",
      "    \"categories\": [],\n",
      "    \"table\": [\n",
      "      [],\n",
      "      []\n",
      "    ],\n",
      "    \"row_sums\": [\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    \"col_sums\": [],\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Quick peek at outputs (if created)\n",
    "from pathlib import Path\n",
    "out1 = Path('analysis/analysis_summary.json')\n",
    "out2 = Path('analysis/chi_square_results.json')\n",
    "if out1.exists():\n",
    "    print('analysis_summary.json:')\n",
    "    txt = out1.read_text()\n",
    "    print(txt[:1000] + ('...' if len(txt)>1000 else ''))\n",
    "else:\n",
    "    print('analysis_summary.json not found yet.')\n",
    "if out2.exists():\n",
    "    print('\\nchi_square_results.json:')\n",
    "    txt2 = out2.read_text()\n",
    "    print(txt2[:1000] + ('...' if len(txt2)>1000 else ''))\n",
    "else:\n",
    "    print('chi_square_results.json not found yet.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2ac0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
