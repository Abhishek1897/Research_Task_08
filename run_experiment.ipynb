{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf111c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ready. Results will be saved to: results\\responses.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "run_experiment.ipynb (Jupyter version)\n",
    "Logs manually pasted LLM responses to results/responses.csv\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import csv, os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the results file path (same as Python version)\n",
    "RESULTS_CSV = Path(\".\") / \"results\" / \"responses.csv\"\n",
    "RESULTS_CSV.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Ensure header exists\n",
    "if not RESULTS_CSV.exists():\n",
    "    with open(RESULTS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"timestamp\",\"provider\",\"model\",\"model_version\",\"hypothesis_id\",\"prompt_file\",\"temperature\",\"seed\",\"response_text\",\"tokens\"])\n",
    "\n",
    "print(f\"✅ Ready. Results will be saved to: {RESULTS_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7daad863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159a7b14922a4bba95423ee1e9b1db01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Provider:', placeholder='OpenAI / Anthropic / Google')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cbc7a5382249518364668c2b292418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Model:', placeholder='GPT-4o / Claude 3.5 / Gemini 1.5')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f9f7ef96f482f8da536ff729e941a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Version:', placeholder='e.g., Oct-2025')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50013d33e0a4ce581c21757b14b8c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Hypothesis:', placeholder='H1_framing_negative')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a86a22da3e4fafbd848fef277578be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Prompt File:', placeholder='prompts/H1_framing_negative.txt')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a688f51348144a4586520feb7cac7baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Temperature:', placeholder='0.2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3c62f5fc0842d39a89101e742fa47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Seed:', placeholder='optional')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62123ecc8df6470ab5a3a89baf13a054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Response:', layout=Layout(height='200px', width='100%'), placeholder='Paste th…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec1529336bd471ca1a6a3a48e1b9656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Tokens:', placeholder='optional')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11010d2f6a1548999f7e9964b8adaedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Response', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0b95cfe9c84864aa564743735d3600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive manual entry cell\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "provider = widgets.Text(description=\"Provider:\", placeholder=\"OpenAI / Anthropic / Google\")\n",
    "model = widgets.Text(description=\"Model:\", placeholder=\"GPT-4o / Claude 3.5 / Gemini 1.5\")\n",
    "model_version = widgets.Text(description=\"Version:\", placeholder=\"e.g., Oct-2025\")\n",
    "hypothesis_id = widgets.Text(description=\"Hypothesis:\", placeholder=\"H1_framing_negative\")\n",
    "prompt_file = widgets.Text(description=\"Prompt File:\", placeholder=\"prompts/H1_framing_negative.txt\")\n",
    "temperature = widgets.Text(description=\"Temperature:\", placeholder=\"0.2\")\n",
    "seed = widgets.Text(description=\"Seed:\", placeholder=\"optional\")\n",
    "response_text = widgets.Textarea(description=\"Response:\", placeholder=\"Paste the model response here\", layout=widgets.Layout(width='100%', height='200px'))\n",
    "tokens = widgets.Text(description=\"Tokens:\", placeholder=\"optional\")\n",
    "button = widgets.Button(description=\"Save Response\", button_style=\"success\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_click(b):\n",
    "    data = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"provider\": provider.value,\n",
    "        \"model\": model.value,\n",
    "        \"model_version\": model_version.value,\n",
    "        \"hypothesis_id\": hypothesis_id.value,\n",
    "        \"prompt_file\": prompt_file.value,\n",
    "        \"temperature\": temperature.value,\n",
    "        \"seed\": seed.value,\n",
    "        \"response_text\": response_text.value.replace(\"\\n\", \" \").strip(),\n",
    "        \"tokens\": tokens.value\n",
    "    }\n",
    "\n",
    "    # Append to CSV\n",
    "    with open(RESULTS_CSV, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data.values())\n",
    "\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"✅ Logged response for {hypothesis_id.value} ({model.value}) at {data['timestamp']}\")\n",
    "        print(f\"Saved to: {RESULTS_CSV}\")\n",
    "\n",
    "button.on_click(on_click)\n",
    "\n",
    "display(provider, model, model_version, hypothesis_id, prompt_file, temperature, seed, response_text, tokens, button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cdbfb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>provider</th>\n",
       "      <th>model</th>\n",
       "      <th>model_version</th>\n",
       "      <th>hypothesis_id</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>temperature</th>\n",
       "      <th>seed</th>\n",
       "      <th>response_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-30T20:42:30.471288</td>\n",
       "      <td>Open AI</td>\n",
       "      <td>GPT 3.5</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H4</td>\n",
       "      <td>H4_selection_stats.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test selection bias</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-10-30T20:44:31.102766</td>\n",
       "      <td>Open AI</td>\n",
       "      <td>GPT 3.5</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H1</td>\n",
       "      <td>H1_framing_negative.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“Player A underperformed, struggling to mainta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-10-30T20:44:47.733320</td>\n",
       "      <td>Open AI</td>\n",
       "      <td>GPT 3.5</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H1</td>\n",
       "      <td>H1_framing_positive.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“Player A showed potential for growth, with im...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-10-30T20:45:21.054282</td>\n",
       "      <td>Open AI</td>\n",
       "      <td>GPT 3.5</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H3</td>\n",
       "      <td>H3_confirmation_primed.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“This confirms the hypothesis that offensive t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-10-30T20:45:39.046557</td>\n",
       "      <td>Open AI</td>\n",
       "      <td>GPT 3.5</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H4</td>\n",
       "      <td>H4_selection_stats.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“Data indicates more focus on early-period sco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp provider    model model_version hypothesis_id  \\\n",
       "5  2025-10-30T20:42:30.471288  Open AI  GPT 3.5      Oct 2025            H4   \n",
       "6  2025-10-30T20:44:31.102766  Open AI  GPT 3.5      Oct 2025            H1   \n",
       "7  2025-10-30T20:44:47.733320  Open AI  GPT 3.5      Oct 2025            H1   \n",
       "8  2025-10-30T20:45:21.054282  Open AI  GPT 3.5      Oct 2025            H3   \n",
       "9  2025-10-30T20:45:39.046557  Open AI  GPT 3.5      Oct 2025            H4   \n",
       "\n",
       "                  prompt_file  temperature  seed  \\\n",
       "5      H4_selection_stats.txt          0.2   NaN   \n",
       "6     H1_framing_negative.txt          0.2   NaN   \n",
       "7     H1_framing_positive.txt          0.2   NaN   \n",
       "8  H3_confirmation_primed.txt          0.2   NaN   \n",
       "9      H4_selection_stats.txt          0.2   NaN   \n",
       "\n",
       "                                       response_text  tokens  \n",
       "5                                Test selection bias     NaN  \n",
       "6  “Player A underperformed, struggling to mainta...     NaN  \n",
       "7  “Player A showed potential for growth, with im...     NaN  \n",
       "8  “This confirms the hypothesis that offensive t...     NaN  \n",
       "9  “Data indicates more focus on early-period sco...     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View your current logged responses\n",
    "if RESULTS_CSV.exists():\n",
    "    df = pd.read_csv(RESULTS_CSV)\n",
    "    display(df.tail())\n",
    "else:\n",
    "    print(\"⚠️ No responses logged yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd2e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
